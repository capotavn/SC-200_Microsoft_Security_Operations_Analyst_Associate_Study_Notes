# 7. Create Detections and Perform Investigations Using Microsoft Sentinel

## I. Threat Detection with Microsoft Sentinel Analytics

### What is Microsoft Sentinel Analytics?

**Overview**
- Detects, investigates, and remediates cybersecurity threats
- Analyzes historical data from workstations, servers, networking devices, firewalls, sensors
- Identifies correlations and anomalies across various data sources
- Triggers alerts based on attack techniques used by known malicious actors

**Common Security Analytics Use Cases**
- Identification of compromised accounts
- User behavior analysis to detect suspicious patterns
- Network traffic analysis to locate potential attack trends
- Detection of data exfiltration by attackers
- Detection of insider threats
- Investigation of incidents
- Threat hunting

**Analytics Home Page**
- **Header bar**: Shows number of currently used rules
- **Rules and templates list**: All preloaded rule templates from Microsoft Sentinel GitHub repository (150+ templates)
- **Details pane**: Explains each template and rule for detection

**Filters Available**
- **Severity**: Filter by levels (High, Medium, Low, Informational)
- **Rule Type**: 7 types - Scheduled, NRT (near real time), Fusion, Microsoft Security, ML Behavior Analytics, Threat Intelligence, Anomaly
- **Tactics**: Filter based on 14 specific methodologies in MITRE ATT&CK model
- **Data Sources**: Filter by data source connector that generates alerts

### Types of Analytics Rules

**Anomaly**
- Informational alerts that identify anomalous behaviors
- Use machine learning to detect unusual activities

**Fusion**
- Uses scalable machine learning algorithms
- Correlates many low-fidelity alerts and events across multiple products into high-fidelity actionable incidents
- Enabled by default, not customizable
- Only one rule can be created with this template
- Can correlate alerts from scheduled analytics rules with alerts from other systems

**Required Data Connectors for Fusion**:
- Out-of-the-box anomaly detections
- Microsoft Entra ID Protection
- Microsoft Defender for Cloud
- Microsoft Defender for IoT
- Microsoft Defender XDR
- Microsoft Defender for Cloud Apps
- Microsoft Defender for Endpoint
- Microsoft Defender for Identity
- Microsoft Defender for Office 365
- Alerts from scheduled analytics rules (must contain kill-chain tactics and entity mapping)

**Common Fusion Attack Detection Scenarios**:
- **Data exfiltration**: Suspicious forwarding rule after suspicious Microsoft Entra sign-in
- **Data destruction**: Anomalous file deletions after suspicious sign-in
- **Denial of service**: Significant VM deletions after suspicious sign-in
- **Lateral movement**: Significant impersonation actions after suspicious sign-in
- **Ransomware**: Unusual user behavior to encrypt data after suspicious sign-in

**Microsoft Security**
- Automatically creates incidents from alerts generated in connected Microsoft security services
- Can configure for high-risk user threat attempts
- Supported solutions: Defender for Cloud Apps, Defender for Server, Defender for IoT, Defender for Identity, Defender for Office 365, Microsoft Entra ID Protection, Defender for Endpoint
- Can filter by severity and specific text in alert name

**ML Behavior Analytics**
- Built-in machine learning behavior analytics rules
- Cannot edit or review rule settings
- Uses Microsoft machine learning algorithms to detect suspicious activity
- Correlates several low-fidelity incidents into high-fidelity security incidents
- Examples: Detect anomalous SSH or RDP sign-in activity

**Scheduled Alerts**
- Provides highest level of customization
- Define custom expressions using Kusto Query Language (KQL)
- Set up schedule for rule to run
- Filter security events based on defined criteria

**NRT (Near Real Time) Rules**
- Provide near real-time detection capabilities
- Run queries every minute for immediate threat response

**Threat Intelligence**
- Uses threat intelligence feeds to detect threats
- Correlates indicators from threat intel with organizational data

### Create Analytics Rule from Templates

**Rule Template Properties**
- **Severity level**: High, Medium, Low, Informational
- **Name**: Meaningful name for alert rule
- **Rule type**: Anomaly, Fusion, Microsoft Security, ML Behavior Analytics, Scheduled, NRT
- **Data Source**: Data source connector that generated alert
- **Tactics**: MITRE ATT&CK methodologies used by malware

**Templates display "IN USE" label** when actively used

**Creating Microsoft Security Rule**

**General Tab Fields**:
- Name (prepopulated from template)
- Description (details about alert creation)
- Status (enabled/disabled)
- Microsoft security service (alert source)
- Filter by severity (custom: High, Medium, Low, Informational)
- Include specific alerts (add words to include)
- Exclude specific alerts (add words to exclude)

**Automated Response Tab**:
- Automation rule name
- Trigger (predefined, unchangeable)
- Conditions (query filter construct)
- Actions (selection list of actions)
- Rule expiration (default: indefinite)
- Order (sequential numbers to reorder rules)

### Create Custom Scheduled Analytics Rule

**General Tab**:
- **Name**: Descriptive name for suspicious activity alert
- **Description**: Detailed description for other analysts
- **Tactics**: Choose from available attack categories (MITRE tactics)
- **Severity**: High, Medium, Low, Informational
- **Status**: Enable (default) or Disable

**Set Rule Logic Tab**:

**Rule Query**: Define detection method using KQL code
- Example query (anomalous Azure resource creation):
```kql
AzureActivity
| where OperationName == "MICROSOFT.COMPUTE/VIRTUALMACHINES/WRITE"
| where ActivityStatus == "Succeeded"
| make-series dcount(ResourceId) default=0 on EventSubmissionTimestamp in range(ago(7d), now(), 1d) by Caller
```

**Alert Enrichment** (Preview):
- **Entity mapping**: Define up to 5 entities from query results for in-depth analysis (user, host, IP address)
- **Custom details**: Set key-value pairs to display event parameters
- **Alert details**: Free text parameters for each alert instance

**Query Scheduling**:
- Configure run frequency
- Define how far back to search data
- Important: Don't search data older than query run frequency (prevents duplicate alerts)

**Alert Threshold**:
- Specify number of positive results before generating alert
- Logical operators: Is greater than, Is fewer than, Is equal to, Isn't equal to

**Event Grouping**:
- **Group all events into single alert** (default): Creates one alert if query returns more results than threshold
- **Trigger alert for each event**: Creates unique alerts for each event

**Suppression**:
- Stop running query after alert generated (On/Off)
- When On, pauses creation of additional incidents for specified duration

**Incident Settings** (Preview):

**Alert Grouping Options**:
- Group if all entities match (recommended)
- Group all alerts into single incident
- Group if selected entities match (e.g., source/target IP addresses)
- Reopen closed matching incidents if another alert generated

**Automated Response Tab**:
- Select existing automation rule or create new one
- Automation rules run playbooks based on chosen triggers and conditions

**Review and Create Tab**:
- Review all configured settings before creating rule

### Manage Analytics Rules

**Four Actions on Existing Active Rules**:

**1. Edit Rules**
- Navigate same pages as rule creation
- Previous inputs preserved
- Modify any rule properties
- Typical modification: Attach automated response
- Example: Attach playbook to change incident status or add comments

**2. Disable Rules**
- Temporarily disable when performing activities that may trigger alerts
- Disabled rules retain configuration
- Can re-enable later

**3. Duplicate Rules**
- Contains all configuration from original rule
- Modify based on requirements
- Default name: Original name + "Copy" appended
- Change name to avoid confusion

**4. Delete Rules**
- Prompts for confirmation before removal
- Permanent action with no undo
- Recommendation: Disable first for period of time before deleting
- Use when service/resource no longer in use

## II. Automation in Microsoft Sentinel

### Understanding Automation Options

**Automation Rules**
- Centrally manage automation of incident handling
- Automate responses for multiple analytics rules at once
- Automatically tag, assign, or close incidents without playbooks
- Control order of actions executed
- Streamline automation use in Microsoft Sentinel
- Simplify complex workflows for incident orchestration

**Playbooks**
- Collection of response and remediation actions and logic
- Run from Microsoft Sentinel as routine
- Automate and orchestrate threat response
- Integrate with internal and external systems
- Run automatically in response to specific alerts/incidents (when triggered by analytics rule or automation rule)
- Run manually on-demand from incidents page
- Based on workflows built in Azure Logic Apps
- Leverage Logic Apps integration capabilities, design tools, scalability, reliability, and Tier 1 Azure service level

### Create Automation Rules

**Overview**
- Centrally manage incident handling automation
- Perform simple automation tasks without playbooks
- Actions: Assign incidents, tag incidents, change status, close incidents
- Automate responses for multiple analytics rules
- Control action execution order
- Run playbooks for complex automation tasks

**Creating and Managing Automation Rules**

**Three Creation Points**:

**1. Automation Blade**
- Centrally manage all automation rules
- View all rules: status (Enabled/Disabled), applied analytics rules
- Create rules applying to many analytics rules
- From top menu: Create > Add new rule
- Complete flexibility: Apply to any analytics rules (including future), define widest range of conditions/actions
- Drag rules to change execution order
- Enable or disable rules

**2. Analytics Rule Wizard**
- Automated response tab shows automation rules for specific analytics rule
- Can create/edit automation rules
- Create/edit rule type: Scheduled query rule or Microsoft incident creation rule
- Create new automation rule: Analytics rule condition already set (unavailable for editing)
- All other configuration options available

**3. Incidents Blade**
- Create automation rule responding to single, recurring incident
- Useful for creating suppression rule for automatically closing "noisy" incidents
- Select incident from queue > Create automation rule from top menu
- Auto-populated fields: Rule name (same as incident), analytics rule, available entities as conditions
- Default action: Suppression (closing)
- Suggested expiration date
- Can add/remove conditions, actions, change expiration date

**Automation Rule Components**:

**Trigger**:
- Automation rules triggered by incident creation
- Incidents created from alerts by analytics rules

**Conditions**:
- Complex sets of conditions can be defined
- Govern when actions should run
- Based on incident/entity states or values
- Include AND/OR/NOT/CONTAINS operators

**Actions** (defined when conditions met):
- **Change incident status**: Keep workflow up to date
- **Change to "closed"**: Specify closing reason and add comment (tracks performance, reduces false positives)
- **Change incident severity**: Reevaluate and reprioritize based on entity presence/absence/values/attributes
- **Assign incident to owner**: Direct incidents to best-suited or most available personnel
- **Add tag to incident**: Classify by subject, attacker, or common denominator
- **Run playbook**: Execute more complex response actions, including external system integration

Only playbooks activated by incident trigger available for use in automation rules
Can define multiple playbooks and combinations of playbooks/actions, and execution order
Playbooks using Logic Apps (Standard or Consumption) available to run from automation rules

**Expiration Date**:
- Define expiration date on automation rule
- Rule disabled after date
- Useful for handling "noise" incidents from planned, time-limited activities (e.g., penetration testing)

**Order**:
- Define execution order of automation rules
- Later rules evaluate incident based on state after previous rules
- Example: If "First Automation Rule" changes severity from Medium to Low, "Second Automation Rule" (defined for Medium or higher) won't run on that incident

## III. Threat Response with Microsoft Sentinel Playbooks

### What are Microsoft Sentinel Playbooks?

**Microsoft Sentinel as SIEM and SOAR**
- **SIEM (Security Information and Event Management)**: Storage and analysis of logs, events, alerts from other systems
- **SOAR (Security Orchestration, Automation and Response)**: Supports vulnerability remediation and security process automation

**Microsoft Sentinel Playbooks**
- Security playbooks are collections of procedures based on Azure Logic Apps
- Run in response to alerts
- Can run manually during incident investigation or automatically when alert triggered
- Automate security operations and make SOC more productive
- Example workflows: Block suspicious username from nonsecure IP address, notify SecOps team about high-level alerts

**Azure Logic Apps**
- Cloud service automating business processes
- Use Logic Apps Designer (graphical design tool) to arrange prebuilt components
- Can also use code view and write in JSON file

**Logic Apps Connector**
- Component providing interface to external service
- Different from Microsoft Sentinel data connector
- Logic Apps connector provides API connection for external service
- Allows integration of events, data, actions across apps, services, systems, protocols, platforms

**Triggers and Actions**:
- **Trigger**: Event occurring when specific conditions satisfied; activates automatically when conditions met
- **Action**: Operation performing task in Logic Apps workflow; runs when trigger activates, another action completes, or condition met

**Microsoft Sentinel Logic Apps Connector**:

**Two Triggers**:
1. When a response to a Microsoft Sentinel alert is triggered
2. When Microsoft Sentinel incident creation rule is triggered

**Available Actions**:

| Name | Description |
|------|-------------|
| Add comment to incident | Adds comments to selected incident |
| Add labels to incident | Adds labels to selected incident |
| Alert - Get incident | Returns incident associated with selected alert |
| Change incident description | Changes description for selected incident |
| Change incident severity | Changes severity for selected incident |
| Change incident status | Changes status for selected incident |
| Change incident title (V2) | Changes title for selected incident |
| Entities - Get Accounts | Returns list of accounts associated with alert |
| Entities - Get FileHashes | Returns list of File Hashes associated with alert |
| Entities - Get Hosts | Returns list of hosts associated with alert |
| Entities - Get IPs | Returns list of IPs associated with alert |
| Entities - Get URLs | Returns list of URLs associated with alert |
| Remove labels from incident | Removes labels for selected incident |

Actions with (V2) or higher number provide new version and may differ from old functionality

Some actions require integration with other connectors (e.g., combine Entities - Get Accounts with For Each action)

### Trigger a Playbook in Real-Time

**Explore the Playbooks Page**
- View all playbooks created from Azure Logic Apps
- Trigger kind column shows connector types used in logic app

**Header Bar Options**:
- **Add Playbook**: Create new playbook
- **Refresh**: Refresh display after creating new playbook
- **Time field dropdown**: Filter status of running playbooks
- **Enable, Disable, Delete**: Available when one or more logic apps selected
- **Logic Apps documentation**: Links to official Microsoft documentation

**Creating New Playbook**:
1. Select Add Playbook
2. Directed to create new logic app page
3. Provide inputs:
   - **Subscription**: Contains Microsoft Sentinel
   - **Resource Group**: Use existing or create new
   - **Logic App name**: Descriptive name
   - **Location**: Same as Log Analytics workspace location
   - **Log Analytics**: Enable to get runtime events information
4. Select Review + Create > Create

**Logic Apps Designer**

**Design Canvas**:
- Add trigger and actions to workflow
- Configure trigger from Microsoft Sentinel Connector when new security incident created
- Provides many predefined templates
- Start with Blank Logic App template to design from scratch

**Microsoft Sentinel Triggers**:
- When a response to a Microsoft Sentinel alert is triggered
- When Microsoft Sentinel incident creation rule was triggered

**Authorization**:
- First time opening Microsoft Sentinel Connector prompts to sign in
- Sign in with Microsoft Entra ID account or Service Principal
- Establishes API connection to Microsoft Entra ID
- API connections store variables and tokens for API access

**Building Playbook Workflow**:
1. Start with trigger from Microsoft Sentinel connector
2. Add actions defining automated response
3. Combine actions from Microsoft Sentinel connector with other Logic Apps connectors
4. Example workflow: Incident trigger > Identify entities > Send email to Office 365 account
5. Each action created as New Step

**Dynamic Content**:
- Use Dynamic content list populated with outputs from previous step
- Example: Microsoft Sentinel connector trigger provides properties like Entities, Alert Display name

**Control Actions Group**:
- Let logic app make decisions
- Include: Logical conditions, switch case conditions, loops
- **Condition action**: If statement with Boolean expression and two actions
- At runtime, execution engine evaluates expression and chooses action (true/false)
- Example: Based on user input, playbook changes alert status or sends email

**After Design Completion**:
- Save logic app to create playbook in Microsoft Sentinel

**Logic Apps Page in Microsoft Sentinel**

**Header Bar Actions**:
- **Run Trigger**: Test playbook
- **Refresh**: Refresh status to retrieve activity status
- **Edit**: Further edit playbook in Logic Apps Designer
- **Delete**: Delete if not needed
- **Disable**: Temporarily prevent action even if trigger activated
- **Update Schema**: Update schema after significant logic change
- **Clone**: Make copy for further modification
- **Export**: Export to Microsoft Power Automate and Power Apps

**Page Sections**:
- **Essentials**: Descriptive information (logic app definition shows trigger and action count)
- **Summary**: Summarized information, links to Logic Apps Designer, trigger history
- **Runs history**: Previous runs and success/failure status

**Automate Response to Incident**:
- Final step: Attach playbook to analytics rule
- Use Automated Response section in analytics rule to select playbook for automatic execution when alert generated

### Run Playbooks On Demand

**On-Demand Playbooks**
- Run based on incident details
- Trigger specific steps during investigation
- Conduct remediation actions

**Use Case Example**:
- False positive incident: Users accessing resources over VPN while connected to office computers
- Cloud Security tags users as medium risk for atypical travel locations
- Use playbook to automatically dismiss risky user property in Microsoft Entra ID

**Microsoft Sentinel Repository on GitHub**
- Contains ready-to-use playbooks
- Help automate responses on incidents
- Defined with ARM templates using Logic App Microsoft Sentinel triggers
- Example: Dismiss-AADRiskyUser playbook

**Deployment from GitHub**:
- Must authorize each connection before editing in Logic Apps Designer
- Authorization creates API connection to appropriate connector
- Stores token and variables
- API connection located in resource group where logic app created
- Connection names appended with azuresentinel prefix
- Can edit connection in Logic Apps Designer

**Attach Playbook to Existing Incident**:
1. Open Incident page in Microsoft Sentinel
2. Select existing incident
3. In details pane, select View full details
4. From Alerts panel, select View playbooks
5. Run one of existing playbooks
6. After investigation, manually run playbook to respond to security threat

## IV. Security Incident Management in Microsoft Sentinel

### Understanding Incidents

**Incident Management Concepts**

**Key Concepts**:
- **Data connectors**: Ingest and collect data from security-related services (Linux/Windows computers with Log Analytics agent, syslog servers for firewalls/proxies, direct from Azure services); forward to Log Analytics workspace
- **Events**: Stored in Log Analytics workspace; contain details of security-related activity to monitor
- **Analytics rules**: Detect important security events and generate alerts; created using built-in templates or custom KQL queries against Log Analytics workspaces
- **Alerts**: Generated by analytics rules when detecting important security events; can be configured to generate incidents
- **Incidents**: Created from analytics rule alerts; can contain multiple related alerts; used as starting point and tracking mechanism for investigation

**Microsoft Sentinel Overview Page**:
- Incident management begins here
- Review current Microsoft Sentinel environment
- Shows list of most recent incidents
- Displays other important Microsoft Sentinel information
- Understand general security situation before investigating incidents

### Incident Evidence and Entities

**Incident Evidence**

Evidence consists of security event information and related Microsoft Sentinel assets identifying threats

**Events**:
- Link back to one or more specific events from Log Analytics workspace
- Workspaces typically contain thousands of events (too numerous to manually parse)
- When analytics rule query returns events, events attached to generated incident for potential review
- Use to understand incident scope and frequency before further investigation

**Alerts**:
- Most incidents generated because of analytics rule alert
- Examples: Detection of suspicious files, suspicious user activities, attempted privilege elevation
- Analytics rules generate alerts based on: KQL queries or direct connection to Microsoft Security solutions (Defender for Cloud, Defender XDR)
- If alert grouping enabled, Microsoft Sentinel includes any related alert evidence for incident

**Bookmarks**:
- While investigating, identify events to track or mark for later investigation
- Preserve queries run in Log Analytics by choosing events and designating as bookmarks
- Record notes and tags to better inform future threat-hunting processes
- Available to you and teammates

**Incident Entities**

Entity refers to network or user resource involved with event; used as entry points to explore all alerts and correlations associated with that entity

**Entity Relationships**:
- Useful when investigating incidents
- Instead of analyzing identity alerts, network alerts, data access alerts individually, use entities to observe all alerts associated with particular user, host, or address

**Entity Types Include**:
- Account
- Host
- IP
- URL
- FileHash

**Example Use**:
- Identify all alerts associated with specific user
- User's host machine
- Other hosts user connected to
- IP addresses associated with user
- Expose which events and alerts could be part of same attack

### Manage Incidents

**Review Incidents**

**Incidents Page**:
- Provides complete list of incidents in Microsoft Sentinel
- Basic incident information: Severity, ID, title, alerts, product names, created time, last update time, owner, status
- Sort by any incident column
- Filter by: Name, severity, status, product name, owner

**Important**: Microsoft Entra users investigating incidents must be members of Directory Reader role

**Examine Incident Details**:
- Select any incident to display more information in right pane
- Pane provides: Incident description, related evidence, entities, tactics
- Contains links to: Associated workbooks, analytics rule that generated incident
- Information helps clarify incident nature, context, and course of action

**View Full Details**:
- Select View full details in incident details pane
- Opens Incident page with more details
- Better understand incident context
- Example: In brute force attack, go to Log Analytics query to determine number of attacks

**Manage Incident Metadata**

**Ownership**:
- Each incident assigned owner from security team
- Incident owner responsible for: Overall management, investigation, status updates
- Can change ownership anytime to assign to another team member for further investigation or escalation

**Status**:
- Every new incident assigned status of "New"
- Manually change status to reflect current state
- Status options:
  - **New**: Initial status
  - **Active**: Under investigation
  - **Closed**: Fully resolved

**When Closing Incident, Choose Resolution**:
- True Positive - Suspicious activity
- Benign Positive - Suspicious but expected
- False Positive - Incorrect alert logic
- False Positive - Inaccurate data
- Undetermined

**Severity**:
- Rule or Microsoft security source initially sets severity
- Severity usually remains unchanged
- Can change if incident more or less severe than initially classified
- Severity options: Informational, Low, Medium, High

**Use the Investigation Graph**:
- Select Investigate on Incident page
- Opens investigation graph (visual tool)
- Identifies entities involved in attack
- Shows relationships between entities
- If incident involves multiple alerts over time, review alert timeline and correlations between alerts

**Review Entity Details**:
- Select each entity on graph to observe more information
- Information includes: Relationships to other entities, account usage, data flow information
- For each information area: Go to related events in Log Analytics, add related alert data into graph

**Review Incident Details**:
- Select incident item on graph
- Observe incident metadata related to security and environment context

## V. Identify Threats with Behavioral Analytics

### Understanding Behavioral Analytics

**Entity Behavior Capability**

**Challenges**:
- Identifying threats inside organization time-consuming and labor-intensive
- Sifting through alerts, connecting dots, active hunting: Massive amounts of time with minimal returns
- Sophisticated threats may evade discovery (zero-day, targeted, advanced persistent threats)

**Entity Behavior Eliminates**:
- Drudgery from analysts' workloads
- Uncertainty from efforts
- Delivers high-fidelity and actionable intelligence
- Focus on investigation and remediation

**How It Works**:
- Collects logs and alerts from all connected data sources
- Analyzes and builds baseline behavioral profiles of organization's entities (users, hosts, IP addresses, applications, etc.)
- Analysis across time and peer group horizon
- Uses various techniques and machine learning capabilities
- Identifies anomalous activity
- Determines if asset compromised
- Figures out relative sensitivity of particular assets
- Identifies peer groups of assets
- Evaluates potential impact of compromised asset ("blast radius")
- Effectively prioritize investigation and incident handling

**Security-Driven Analytics**

**Microsoft Sentinel's "Outside-In" Approach (Gartner UEBA paradigm)**:

**Three Frames of Reference**:

**1. Use Cases**:
- Prioritizes relevant attack vectors and scenarios
- Based on security research aligned with MITRE ATT&CK framework (tactics, techniques, subtechniques)
- Identifies various entities: Victims, perpetrators, pivot points in kill chain
- Focuses on most valuable logs each data source can provide

**2. Data Sources**:
- First and foremost supports Azure data sources
- Thoughtfully selects third-party data sources
- Provides data matching threat scenarios

**3. Analytics**:
- Uses machine learning algorithms
- Identifies anomalous activities
- Presents evidence clearly and concisely in form of contextual enrichments

**Contextual Analysis**:
- Presents artifacts helping security analysts get clear understanding of anomalous activities in context
- Comparison with user's baseline profile
- Actions evaluated contextually where "true" outcome indicates identified anomaly:
  - Across geographical locations, devices, environments
  - Across time and frequency horizons (compared to user's own history)
  - Compared to peers' behavior
  - Compared to organization's behavior

**Scoring**:
- Each activity scored with "Investigation Priority Score"
- Determines probability of specific user performing specific activity
- Based on behavioral learning of user and peers
- Most abnormal activities receive highest scores (scale 0-10)

### Explore Entities

**Entity Identification**

When alerts sent to Microsoft Sentinel, include data elements that Microsoft Sentinel identifies and classifies as entities (user accounts, hosts, IP addresses, others)

**Identification Challenges**:
- Occasionally challenging if alert doesn't contain sufficient entity information
- User accounts identified multiple ways: Microsoft Entra GUID, UPN value, or username + NT domain name combination
- Different data sources identify same user differently
- Microsoft Sentinel merges identifiers into single entity when possible

**Risk Scenario**:
- Resource provider creates alert with insufficiently identified entity (e.g., username without domain context)
- User entity can't merge with other instances of same user account
- Identified as separate entity
- Two entities remain separate instead of unified

**Best Practices**:
- Verify all alert providers properly identify entities in produced alerts
- Synchronizing user account entities with Microsoft Entra ID creates unifying directory
- Directory able to merge user account entities

**Entity Types Currently Identified**:
- User account (Account)
- Host
- IP address (IP)
- Malware
- File
- Process
- Cloud application (CloudApplication)
- Domain name (DNS)
- Azure resource
- File (FileHash)
- Registry key
- Registry value
- Security group
- URL
- IoT device
- Mailbox
- Mail cluster
- Mail message
- Submission mail

**Entity Pages**

**Access**:
- When encounter any entity (currently limited to users and hosts) in search, alert, or investigation
- Select entity to be taken to entity page
- Datasheet full of useful information about entity

**Three Parts**:

**1. Left-Side Panel**:
- Entity's identifying information
- Collected from data sources: Microsoft Entra ID, Azure Monitor, Defender for Cloud, Defender XDR

**2. Center Panel**:
- Graphical and textual timeline of notable events related to entity
- Events include: Alerts, bookmarks, activities
- Activities are aggregations of notable events from Log Analytics
- Queries detecting activities developed by Microsoft security research teams

**3. Right-Side Panel**:
- Behavioral insights on entity
- Quickly identify anomalies and security threats
- Insights developed by Microsoft security research teams
- Based on anomaly detection models

**The Timeline**

**Major Contribution**:
- Presents story about entity-related events
- Understand entity's activity within specific time frame

**Features**:
- Choose time range from preset options (last 24 hours) or custom-defined time frame
- Set filters limiting information to specific event types or alerts

**Included Items**:
- **Alerts**: Any alerts where entity defined as mapped entity (if custom alerts created, ensure entity mapping done properly)
- **Bookmarks**: Any bookmarks including specific entity shown on page
- **Activities**: Aggregation of notable events relating to entity

**Entity Insights**

**Overview**:
- Queries defined by Microsoft security researchers
- Help analysts investigate more efficiently and effectively
- Presented as part of entity page
- Provide valuable security information on hosts and users
- Form: Tabular data and charts

**Benefits**:
- Information here means no detour to Log Analytics
- Includes data: Sign-ins, group additions, anomalous events, more
- Includes advanced ML algorithms to detect anomalous behavior

**Data Types for Insights**:
- Syslog
- SecurityEvent
- Audit Logs
- Sign-in Logs
- Office Activity
- BehaviorAnalytics (UEBA)

### Display Entity Behavior Information

**Entity Behavior Page**

**Features**:
- Search for entities or select from list of already displayed entities
- Once selected, Entity page displayed with information and timeline of alerts and activities

**Incident Investigation Graph**:
- Includes option for Insights
- Insights display information from Entity behavior data

**How to Use Entity Pages**

**Usage Scenarios**:
- Part of multiple usage scenarios
- Can be accessed from:
  - Incident management
  - Investigation graph
  - Bookmarks
  - Directly from entity search page under Entity behavior analytics in Microsoft Sentinel main menu

### Use Anomaly Detection Analytical Rule Templates

**Overview**

**Cybersecurity Arms Race**:
- Attackers constantly finding ways to evade detection
- Attacks result in unusual behavior in systems being attacked

**Microsoft Sentinel's Customizable ML-Based Anomalies**:
- Identify unusual behavior with analytics rule templates
- Work right out of the box

**Uses for Anomalies**:

**1. Additional Signals to Improve Detection**:
- Detect new threats
- Make existing detections more effective
- Single anomaly not strong signal of malicious behavior
- Combined anomalies at different kill chain points: Cumulative effect much stronger
- Enhance existing detections by making unusual behavior identified by anomalies a condition for alerts

**2. Evidence During Investigations**:
- Use anomalies during investigations
- Help confirm breach
- Find new investigation paths
- Assess potential impact
- Reduce time security analysts spend on investigations

**3. Start of Proactive Threat Hunts**:
- Use anomalies as context to determine if queries uncovered suspicious behavior
- When behavior suspicious, anomalies point toward potential paths for further hunting
- Reduce both time to detect threat and chance to cause harm

**Anomaly Benefits**:
- Powerful tools but notoriously noisy
- Typically require tedious tuning for specific environments or complex post-processing
- Microsoft Sentinel customizable anomaly templates:
  - Tuned by data science team for out-of-box value
  - Simple tuning process if needed (no ML knowledge required)
  - Thresholds and parameters configurable through familiar analytics rule UI
  - Compare original vs new threshold performance within interface
  - Test during flighting phase
  - Promote to production with button click

**Work with Anomaly Detection Analytics Rules**

**Access**:
1. From Microsoft Sentinel navigation menu, select Analytics
2. On Analytics page, select Rule templates tab
3. Filter list for Anomaly templates: Rule type filter > Unmark Select all > Mark Anomaly > OK

**Template Information**:
- **Description**: How anomaly works and required data
- **Data sources**: Type of logs needed for analysis
- **Tactics and techniques**: MITRE ATT&CK framework coverage
- **Parameters**: Configurable attributes
- **Threshold**: Configurable value for unusual event degree before anomaly created
- **Rule frequency**: Time between log processing jobs
- **Anomaly version**: Template version used by rule (change version requires recreating rule)
- **Template last updated**: Date anomaly version changed

**Activate Anomaly Rules**:

1. Choose rule template not labeled IN USE
2. Select Create rule button (opens rule creation wizard)
3. Wizard has three steps/tabs: General, Configuration, Review and create
4. Can't change values in wizard initially; must create and activate rule first
5. Cycle through tabs
6. Wait for "Validation passed" message on Review and create tab
7. Select Create
8. Can only create one active rule from each template
9. Once completed, active anomaly rule created in Active rules tab
10. Template in Rule templates tab marked IN USE
11. Detected anomalies stored in Anomalies table in Logs section
12. Each rule has training period; anomalies won't appear until after training period (found in rule description)

**Assess Anomaly Quality**:

1. From Microsoft Sentinel navigation menu, select Analytics
2. Check Active rules tab selected
3. Filter list for Anomaly rules
4. Select rule to assess, copy name from top of details pane
5. From Microsoft Sentinel navigation menu, select Logs
6. Close Queries gallery if it pops up
7. Select Tables tab on left pane
8. Set Time range filter to Last 24 hours
9. Use KQL query:
```kql
Anomalies
| where AnomalyTemplateName contains "rule_name_here"
```
10. Select Run

**When Results Available**:
- Expand results for each anomaly
- Expand AnomalyReasons field (tells why anomaly fired)
- "Reasonableness" or "usefulness" may depend on environment conditions
- Common reason for too many anomalies: Threshold too low

**Tune Anomaly Rules**:

**Why Tune**:
- Anomaly rules engineered for maximum effectiveness out of box
- Every situation unique, sometimes rules need tuning

**Process**:
1. Can't edit original active rule
2. Must first duplicate active anomaly rule
3. Customize the copy
4. Original rule keeps running until disabled or deleted (by design for comparison)
5. Duplicate rules disabled by default
6. Can only make one customized copy of any anomaly rule

**Steps to Tune**:
1. Select anomaly rule in Active rules tab
2. Right-click row or left-click ellipsis (...), then select Duplicate
3. New copy has suffix " - Customized" in rule name
4. To customize, select rule and select Edit
5. Opens Analytics rule wizard to change parameters and threshold
6. Parameters vary with each anomaly type and algorithm
7. Preview results in Results preview pane
8. Select Anomaly ID to see why ML model identifies anomaly
9. Enable customized rule to generate results (some changes may require rerun)
10. Customized rule runs in Flighting (testing) mode by default
11. Original rule continues in Production mode by default

**Compare Results**:
1. Go to Anomalies table in Logs
2. Assess new rule (look for original rule name and duplicate with " - Customized" in AnomalyTemplateName column)
3. If satisfied with customized rule results:
   - Go to Active rules tab
   - Select customized rule
   - Select Edit button
   - On General tab, switch from Flighting to Production
   - Original rule automatically changes to Flighting (can't have two versions in production simultaneously)

## VI. Data Normalization in Microsoft Sentinel

### Understanding Data Normalization

**Challenge**:
- Microsoft Sentinel ingests data from many sources
- Working with various data types and tables requires understanding each
- Write and use unique sets of data for analytics rules, workbooks, hunting queries for each type
- Sometimes need separate rules, workbooks, queries even when data types share common elements (e.g., firewall devices)
- Correlating between different data types during investigation and hunting challenging

**Advanced Security Information Model (ASIM)**

**Overview**:
- Layer located between diverse sources and user
- Follows robustness principle: "Be strict in what you send, be flexible in what you accept"
- Transforms Microsoft Sentinel's inconsistent, hard-to-use source telemetry to user-friendly data

**Common ASIM Usage**:

**1. Cross-Source Detection**:
- Normalized analytics rules work across sources (on-premises and cloud)
- Detect attacks like brute force or impossible travel across systems (Okta, AWS, Azure)

**2. Source Agnostic Content**:
- Built-in and custom content using ASIM automatically expands to any ASIM-supporting source
- Works even if source added after content creation
- Example: Process event analytics support any source for data ingestion (Defender for Endpoint, Windows Events, Sysmon)

**3. Support for Custom Sources in Built-In Analytics**

**4. Ease of Use**:
- After learning ASIM, writing queries simpler (field names always same)

**ASIM and OSSEM**:
- ASIM aligns with Open Source Security Events Metadata (OSSEM) common information model
- Allows predictable entity correlation across normalized tables
- OSSEM: Community-led project focusing on documentation and standardization of security event logs
- Provides Common Information Model (CIM) for data normalization procedures
- Enables security analysts to query and analyze data across diverse data sources

**ASIM Components**:

| Component | Description |
|-----------|-------------|
| Normalized schemas | Cover standard sets of predictable event types; define fields representing event, normalized column naming convention, standard format for field values |
| Parsers | Map existing data to normalized schemas using KQL functions; many available out-of-the-box; more parsers and modifiable versions deployable from GitHub repository |
| Content for each normalized schema | Includes analytics rules, workbooks, hunting queries; works on any normalized data without source-specific content |

**ASIM Terminology**:

| Term | Description |
|------|-------------|
| Reporting device | System sending records to Microsoft Sentinel; may not be subject system for record |
| Record | Unit of data sent from reporting device; often referred to as log, event, or alert, but can be other data types |
| Content / Content Item | Different, customizable, or user-created artifacts for Microsoft Sentinel (analytics rules, hunting queries, workbooks); content item is one such artifact |

**View ASIM Parsers**:
1. Navigate to Microsoft Sentinel workspace in Azure portal
2. Select Logs from left navigation
3. Expand schema and filter pane (use ellipsis if needed)
4. Select Functions
5. Expand Microsoft Sentinel
6. See functions starting with ASim and Im

### Use ASIM Parsers

**Parsing and Normalization**:
- In Microsoft Sentinel, happens at query time
- Parsers built as KQL user-defined functions
- Transform data in existing tables (CommonSecurityLog, custom logs, Syslog) into normalized schema

**Users use ASIM parsers instead of table names** to:
- View data in normalized format
- Include all schema-relevant data in query

**Built-In vs Workspace-Deployed Parsers**:

| Compare | Built-in | Workspace-deployed |
|---------|----------|-------------------|
| Advantages | Exist in every Microsoft Sentinel instance; usable with other built-in content | New parsers often delivered first as workspace-deployed |
| Disadvantages | Can't be directly modified by users; fewer parsers available | Not used by built-in content |
| When to use | Use in most cases needing ASIM parsers | Use when deploying new parsers or for parsers not yet available out-of-box |

**Recommendation**: Use built-in parsers for schemas where available

**Parser Hierarchy**:

**Two Levels**:
1. **Unifying parser**: Used by user for relevant schema; ensures all schema-relevant data queried
2. **Source-specific parsers**: Called by unifying parser; perform actual parsing and normalization specific for each source

**Naming Conventions**:
- Unifying parser (built-in): `_Im_Schema`
- Unifying parser (workspace-deployed): `imSchema`
- Where Schema = specific schema it serves
- Source-specific parsers also usable independently (e.g., Infoblox-specific workbook uses vimDnsInfobloxNIOS parser)

**Unifying Parsers**

**Usage in Queries**:
- Use unifying parsers to combine all sources normalized to same schema
- Query using normalized fields

**Example (built-in unifying DNS parser)**:
```kql
_Im_Dns(starttime=ago(1d), responsecodename='NXDOMAIN')
| summarize count() by SrcIpAddr, bin(TimeGenerated,15m)
```

Example uses filtering parameters (improves ASIM performance)

**Same Example Without Filtering Parameters**:
```kql
_Im_Dns
| where TimeGenerated > ago(1d)
| where ResponseCodeName =~ "NXDOMAIN"
| summarize count() by SrcIpAddr, bin(TimeGenerated,15m)
```

**Available Unifying Parsers**:

| Schema | Unifying Parser |
|--------|----------------|
| Authentication | imAuthentication |
| Dns | _Im_Dns |
| File Event | imFileEvent |
| Network Session | _Im_NetworkSession |
| Process Event | imProcessCreate and imProcessTerminate |
| Registry Event | imRegistry |
| Web Session | _Im_WebSession |

**Optimizing Parsing Using Parameters**

**Performance Impact**:
- Using parsers may impact query performance
- Primary impact from filtering results after parsing
- Many parsers have optional filtering parameters
- Enable filtering before parsing and enhance query performance

**Benefits**:
- With query optimization and pre-filtering, ASIM parsers often provide better performance compared to not using normalization

**Using Filtering Parameters**:
- When invoking parser, always use available filtering parameters
- Add one or more named parameters to ensure optimal performance
- Each schema has standard set of filtering parameters (documented in schema documentation)
- Filtering parameters entirely optional

**Schemas Supporting Filtering Parameters**:
- Authentication
- DNS
- Network Session
- Web Session

**Important Note**: Every schema supporting filtering parameters supports at least starttime and endtime parameters; using them often critical for optimizing performance

### Understanding Parameterized KQL Functions

**Overview**:
- When calling KQL functions, can provide set of parameters
- Important concept for building ASIM parsers
- Allows filtering function results with dynamic values before returning results

**Example Process**:

**1. Start with Hardcoded Values** (verify query works):
```kql
AzureActivity
| where CategoryValue == "Administrative"
| where TimeGenerated > todatetime("2021/04/05 5:40:01.032 PM")
```

**2. Replace Hardcoded Values with Parameters**:
```kql
AzureActivity
| where CategoryValue == CategoryParam
| where TimeGenerated > DateParam
```

**3. Save Function**:
- Select Save > Save as function
- Enter Function name: AzureActivityByCategory
- Create two parameters:

| Type | Name | Default value |
|------|------|--------------|
| string | CategoryParam | "Administrative" |
| datetime | DateParam | |

**4. Use Function in New Query**:
```kql
AzureActivityByCategory("Administrative", todatetime("2021/04/05 5:40:01.032 PM"))
```

### Create an ASIM Parser

**When to Develop Custom Parsers**:

**1. Device provides events fitting ASIM schema** but source-specific parser not available

**2. ASIM source-specific parsers available** but device sends events differently than expected:
- Source device configured to send events in non-standard way
- Device has different version than ASIM parser supports
- Events collected, modified, forwarded by intermediary system

**Custom Parser Development Process**:

**High-Level Steps**:
1. Collect sample logs
2. Identify schemas events represent
3. Map source event fields to identified schema(s)
4. Develop one or more ASIM parsers for source (filtering parser and parameter-less parser for each relevant schema)
5. Test parser
6. Deploy parsers into Microsoft Sentinel workspaces
7. Update relevant ASIM unifying parser to reference new custom parser
8. Optional: Contribute parsers to primary ASIM distribution (may become available as built-in parsers)

**Collect Sample Logs**:
- Need representative set of logs
- Typically requires setting up source system and connecting to Microsoft Sentinel
- Cloud pay-as-you-go services allow device deployment for development and testing
- Find vendor documentation and log samples to accelerate development
- Ensure broad log format coverage and reduce mistakes

**Representative Set Should Include**:
- Events with different event results
- Events with different response actions
- Different formats for username, hostname, IDs, other fields requiring value normalization

**Mapping**:

**Before Developing Parser**:
- Map information available in source event(s) to identified schema
- Map all mandatory fields and preferably recommended fields
- Try to map any available information to normalized fields
- If not available in selected schema, consider mapping to fields in other schemas
- Map field values at source to normalized values allowed by ASIM
- Original value stored in separate field (e.g., EventOriginalResultDetails)

**Developing Parsers**:

**Develop Both**:
- Filtering parser
- Parameter-less parser for each relevant schema

**Custom Parser as KQL Query**:
- Developed in Microsoft Sentinel Logs page
- Parser query has three parts: Filter > Parse > Prepare fields

**Filtering Relevant Records**:

**Why Filter**:
- Tables in Microsoft Sentinel include multiple event types
- Examples:
  - Syslog table has data from multiple sources
  - Custom tables may include information from single source providing multiple event types fitting various schemas

**Filtering Using `where` Operator**:
- Example: Sysmon event 1 reports process creation (normalized to ProcessEvent schema)
- Sysmon event 1 part of Event table
- Filter:
```kql
Event | where Source == "Microsoft-Windows-Sysmon" and EventID == 1
```

**Important**: Parser should not filter by time; query using parser will apply time range

**Filtering by Source Type Using Watchlist**:

**When Event Doesn't Contain Source Type Information**:
- Example: Infoblox DNS events sent as Syslog messages (hard to distinguish from other Syslog sources)
- Parser relies on list of sources: ASimSourceType watchlist

**Using ASimSourceType Watchlist**:

**1. Include at Beginning of Parser**:
```kql
let Sources_by_SourceType=(sourcetype:string){_GetWatchlist('ASimSourceType') | where SearchKey == tostring(sourcetype) | extend Source=column_ifexists('Source','') | where isnotempty(Source)| distinct Source };
```

**2. Add Filter Using Watchlist** (Infoblox DNS parser example):
```kql
| where Computer in (Sources_by_SourceType('InfobloxNIOS'))
```

**To Use in Your Parser**:
- Replace Computer with field name containing source information (keep Computer for Syslog-based parsers)
- Replace InfobloxNIOS token with value of your choice
- Inform parser users to update ASimSourceType watchlist with your selected value and list of sources sending these events

**Filtering Based on Parser Parameters**:

**When Developing Filtering Parsers**:
- Ensure parser accepts filtering parameters for relevant schema (documented in reference article)
- Use existing parser as starting point (ensures correct function signature)
- Actual filtering code similar for filtering parsers for same schema

**When Filtering**:
- Filter before parsing using physical fields
- If filtered results not accurate enough, repeat test after parsing to fine-tune results
- Do not filter if parameter not defined and still has default value

**String Parameter Filtering Example** (default value usually '*'):
```kql
srcipaddr=='*' or ClientIP==srcipaddr
```

**List Parameter Filtering Example** (default value usually empty list):
```kql
array_length(domain_has_any) == 0 or Name has_any (domain_has_any)
```

**Filtering Optimization**:

**Recommendations**:
- Always filter on built-in rather than parsed fields (easier on parsed fields but dramatically impacts performance)
- Use operators providing optimized performance (particularly ==, has, startswith)
- Operators like contains or matches regex dramatically impact performance

**When Recommendations Hard to Follow**:
- Using has less accurate than contains
- Matching built-in field (SyslogMessage) less accurate than extracted field (DvcAction)
- Recommendation: Pre-filter using performance-optimizing operator over built-in field
- Repeat filter using more accurate conditions after parsing

**Infoblox DNS Parser Snippet Example**:
```kql
Syslog | where ProcessName == "named" and SyslogMessage has "client"
…
| extend Log_Type = tostring(Parser[1]),
| where Log_Type == "client"
```
- First checks SyslogMessage field has word "client"
- Term might be used elsewhere in message
- After parsing Log_Type field, checks again word "client" was indeed field's value

**Parsing**

Once query selects relevant records, may need to parse them if multiple event fields conveyed in single text field

**KQL Parsing Operators** (ordered by performance optimization):

| Operator | Description |
|----------|-------------|
| split | Parse string of delimited values |
| parse_csv | Parse string formatted as CSV line |
| parse | Parse multiple values from arbitrary string using pattern (simplified pattern or regex) |
| extract_all | Parse single values from arbitrary string using regex; similar performance to parse with regex |
| extract | Extract single value from arbitrary string using regex; better performance than parse/extract_all if single value needed; multiple activations over same source string less efficient |
| parse_json | Parse values in string formatted as JSON; if only few values needed, parse/extract/extract_all provides better performance |
| parse_xml | Parse values in string formatted as XML; if only few values needed, parse/extract/extract_all provides better performance |

**Additional Processing**:
- **Formatting and type conversion**: Source field may need formatting to fit target schema field (e.g., convert string to datetime); functions like todatetime, tohex helpful
- **Value lookup**: Source field value may need mapping to normalized values; functions iff and case helpful

**Microsoft DNS Parser Example** (assigns EventResult field):
```kql
extend EventResult = iff(EventId==257 and ResponseCode==0 ,'Success','Failure')
```

**For Several Values** (use datatable and lookup):
```kql
let RCodeTable = datatable(ResponseCode:int,ResponseCodeName:string) [ 0, 'NOERROR', 1, 'FORMERR'....]; 
... 
| lookup RCodeTable on ResponseCode 
| extend EventResultDetails = case ( 
    isnotempty(ResponseCodeName), ResponseCodeName, 
    ResponseCode between (3841 .. 4095), 'Reserved for Private Use', 
    'Unassigned')
```

**Mapping Values**:

**Primary Operator**: extend (alongside string, numerical, date functions)

**When Source-to-Target Value Mapping Needed**:
- Use case, iff, and lookup statements
- Use datatable and lookup when each source value maps to target value

**Mapping Example**:
```kql
let NetworkProtocolLookup = datatable(Proto:real, NetworkProtocol:string)[
    6, 'TCP',
    17, 'UDP'
];
let DnsResponseCodeLookup=datatable(DnsResponseCode:int,DnsResponseCodeName:string)[
    0,'NOERROR',
    1,'FORMERR',
    2,'SERVFAIL',
    3,'NXDOMAIN',
    ...
];
...
| lookup DnsResponseCodeLookup on DnsResponseCode
| lookup NetworkProtocolLookup on Proto
```

**Note**: Lookup useful and efficient even when mapping has only two possible values

**Complex Mapping Conditions** (use iff or case):

**iff Function** (two values):
```kql
| extend EventResult =
    iff(EventId==257 and ResponseCode==0,'Success','Failure')
```

**case Function** (more than two values):
```kql
| extend DnsResponseCodeName =
    case (
        DnsResponseCodeName != "", DnsResponseCodeName,
        DnsResponseCode between (3841 .. 4095), 'Reserved for Private Use',
        'Unassigned'
    )
```

**Prepare Fields in Result Set**:

**Purpose**: Ensure normalized fields used in results

**KQL Operators**:

| Operator | Description | When to Use in Parser |
|----------|-------------|----------------------|
| project-rename | Renames fields | If field exists and only needs rename; renamed field behaves like built-in field with better performance |
| project-away | Removes fields | Remove specific unwanted fields from result set; recommended to not remove original unnormalized fields unless they create confusion or are very large |
| project | Selects fields (existing or created), removes all others | Not recommended for parser; shouldn't remove other unnormalized fields; if need to remove specific fields (temporary values), use project-away |
| extend | Add aliases | Also used for generating calculated fields; used to create aliases |

**Handle Parsing Variants**:

**When to Use**:
- Events in stream include variants requiring different parsing logic

**Two Approaches**:
1. Use conditional statements (iff, case)
2. Use union structure

**Union Structure Approach**:

**Example**:
```kql
let AzureFirewallNetworkRuleLogs = AzureDiagnostics
    | where Category == "AzureFirewallNetworkRule"
    | where isnotempty(msg_s);
    
let parseLogs = AzureFirewallNetworkRuleLogs
    | where msg_s has_any("TCP", "UDP")
    | parse-where
        msg_s with networkProtocol:string
        " request from " srcIpAddr:string
        ":" srcPortNumber:int
    …
    | project-away msg_s;
    
let parseLogsWithUrls = AzureFirewallNetworkRuleLogs
    | where msg_s has_all ("Url:","ThreatIntel:")
    | parse-where
        msg_s with networkProtocol:string
        " request from " srcIpAddr:string
        " to " dstIpAddr:string
    …
    
union parseLogs, parseLogsWithUrls…
```

**Important**:
- Avoid duplicate events and excessive processing
- Each function starts by filtering using native fields for intended events only
- Use project-away at each branch before union if needed

**Deploy Parsers**:

**Manual Deployment**:
- Copy to Azure Monitor Log page
- Save query as function
- Useful for testing

**Large Number Deployment** (use parser ARM templates):

**Steps**:
1. Create YAML file based on relevant template for each schema
2. Include query in YAML file
3. Start with YAML template relevant for schema and parser type (filtering or parameter-less)
4. Use ASIM Yaml to ARM template converter to convert YAML to ARM template
5. If deploying update, delete older function versions using portal or PowerShell tool
6. Deploy template using Azure portal or PowerShell
7. Can combine multiple templates into single deploy process using linked templates

### Configure Azure Monitor Data Collection Rules

**Another Normalization Method**:
- Transform data at ingestion time
- Benefit: Store data in parsed format for use in Microsoft Sentinel

**Data Collection Rules (DCRs)**:
- Provide ETL-like pipeline in Azure Monitor
- Define how data coming into Azure Monitor should be handled
- May specify where data should be sent
- May filter or transform data before stored in Azure Monitor Logs
- Some DCRs created and managed by Azure Monitor
- Others created to customize data collection for specific requirements

**Types of Data Collection Rules**:

**1. Standard DCR**:
- Used with different workflows sending data to Azure Monitor
- Currently supported workflows: Azure Monitor agent and custom logs

**2. Workspace Transformation DCR**:
- Used with Log Analytics workspace
- Apply ingestion-time transformations to workflows not currently supporting DCRs

**Transformations**:
- Allow filtering or modifying incoming data before stored in Log Analytics workspace
- Defined using Kusto Query Language (KQL) statement
- Applied individually to each entry in data source
- Must understand format of incoming data
- Create output in structure of target table

**Transformation Structure**:

Input stream represented by virtual table named "source" with columns matching input data stream definition

**Typical Example Transformation**:
```kql
source
| where severity == "Critical"
| extend Properties = parse_json(properties)
| project
    TimeGenerated = todatetime(["time"]),
    Category = category,
    StatusDescription = StatusDescription,
    EventName = name,
    EventId = tostring(Properties.EventId)
```

**Functionality**:
- Filters incoming data with where statement
- Adds new column using extend operator
- Formats output to match target table columns using project operator

## VII. Query, Visualize, and Monitor Data in Microsoft Sentinel

### Monitor and Visualize Data

**Microsoft Sentinel Logs**:
- Provides access to various logs collected from security connectors
- Collects logs from integrated connectors
- Stores in Azure Log Analytics workspace

**Log Analytics Workspace**:
- Repository storing data and configuration information
- Create queries to filter important information
- Use to create analytics rules and detect threats
- Search data from multiple sources
- Aggregate large data sets
- Perform complex operations to locate security threats and vulnerabilities

**Microsoft Sentinel Logs Page**

**Main Parts**:
1. **Page header**: Links to Queries, settings, help section
2. **Tables pane**: Displays collected data from logs in tables (multiple columns)
3. **Query pane**: Write query expressions
4. **Query result pane**: Displays query results

**Queries**:
- Select Queries link on page header
- New window opens with predefined sample queries
- Filter by: Category, Query Type, Resource Type, Solution, Topic
- Select Run to start predefined query
- Redirects to query pane showing structure and results
- Example: Unauthorized Users predefined query

**Query Explorer**:
- Access previously saved queries
- Access Solution Queries (filter most common queries)
- From Solution Queries list: Run query or organize in favorites (star symbol)

**Tables Pane**:
- Groups logs from different solutions into tables
- Expand solution group to observe collected logs
- Select log from tables pane to: Preview data or add to Favorites section

**Queries Pane**:
- Create queries retrieving data based on provided expression
- Provides suggestions and automatically fills expected query elements
- Use Kusto Query Language (KQL) capabilities
- Example (identify deleted virtual machines):
```kql
AzureActivity
| where OperationName == 'Delete Virtual Machine'
| where ActivityStatus == 'Accepted'
| extend AccountCustomEntity = Caller
| extend IPCustomEntity = CallerIpAddress
```

**Header Toolbar**:

**Features**:
- **Save**: Save query from Query pane (prompts for name and category); saved queries appear in query explorer
- **Time Range**: Change time range for displaying query results
- **Copy link to query**: Create shareable link with team members
- **Copy query text**: Copy query text
- **Create alerts**: New Azure Monitor alert or New Microsoft Sentinel alert (directs to analytics rule creation steps)
- **Export options**:
  - Export to CSV (all columns, visible and hidden)
  - Export to CSV-Displayed Columns (only displayed columns)
  - Export to Power BI (M query) (creates PowerBIQuery.txt file for Power BI)
- **Pin to dashboard**: Pin query results to private or shared dashboard
- **Format query**: Make query more readable

**Note**: Can only export or pin query if query generates data in results section

**Query Results**:
- Under Results, observe query results
- Present results using chart
- Hide and display columns to filter results

### Query Data Using Kusto Query Language

**Kusto Query Language (KQL)**:
- Provides ability to search and filter collected data
- Microsoft Sentinel uses KQL to visualize and analyze data
- Create complex analytical queries including:
  - Calculated columns
  - Join functions
  - Group by aggregates

**Write and Run Basic Queries**:

**Query Definition**:
- Read-only request processing data
- Returns processing results without modifying data or metadata
- Similar to SQL queries
- Uses schema entities organized hierarchically: Databases, tables, columns
- Schema is collection of tables grouped under logical categories
- Queries consist of sequences of query statements delimited by semicolon (;)

**Basic Query Structure**:
- Start with table name or search command
- Example (all records from Event table):
```kql
Event
```

**Pipe Character (|)**:
- Separates commands
- Output of first command becomes input of next command
- Add any number of commands to single query
- Example (retrieve Event records, search for term "error"):
```kql
Event
| search error
```

**Tabular and Scalar Operators**:
```
source1 | operator1 | operator2
```

**Example**:
```kql
AzureActivity
| where OperationName == 'Delete Virtual Machine'
| where ActivityStatus == 'Accepted'
```

**Time Range**:
- Log Analytics limits queries to past 24 hours by default
- Set different time range:
  - Add explicit TimeGenerated filter to query
  - Use Time range control
- Example (data from preceding hour):
```kql
AzureActivity
| where OperationName == 'Delete Virtual Machine'
| where ActivityStatus == 'Accepted'
| where TimeGenerated > ago (1h)
```

**Commonly Used Operators**:
- **count**: Returns count of rows in table
- **take**: Returns up to specified number of data rows
- **project**: Selects subset of columns
- **sort**: Sorts rows into order by one or more columns
- **top**: Returns first N records sorted by specified columns
- **extend**: Computes derived columns
- **summarize**: Aggregates groups of rows
- **render**: Renders results as graphical output

**Combining Records**:
- **join** operator: Combines records from two sources (tables)
- **union** operator: Combines two or more tables into one

**Additional Resources**:
- Log analytics tutorial: Uses features to build and run query
- Azure Data explorer tutorial: Learn about KQL

**Note**: Microsoft Sentinel Log Analytics doesn't support all KQL syntax used in Azure Data Explorer

**Microsoft Sentinel Repository on GitHub**:
- Search for specialized queries and workbooks
- Help secure environment and hunt for threats
- Example query (suspicious delegation of permissions):
```kql
let timeframe = 7d;
AzureActivity
| where TimeGenerated >= ago(timeframe)
| where OperationName == "Create role assignment"
| where ActivityStatus == "Succeeded"
| project Caller, CallerIpAddress
| evaluate basket()
| extend AccountCustomEntity = Caller, IPCustomEntity = CallerIpAddress
```
- Query analyzes IP address where admin grants access
- If operation not from valid IP, signals suspicious activity

**Try Examples**: Use demonstration environment on Azure portal

### Use Default Microsoft Sentinel Workbooks

**Microsoft Sentinel Workbooks**:
- Most data connectors come with their own workbooks
- Get insights into ingested data using tables and visualizations (bar and pie charts)
- Can make own workbooks from scratch instead of predefined templates

**Workbook Page**:
- Access from navigation pane
- Add new workbook
- Review saved workbooks and available templates

**Templates Tab**:
- Access existing workbook templates
- Save workbooks for quick access (appear on My workbooks tab)
- Select existing workbook to display details pane
- Details pane contains: Additional information, required data types, data connectors needed
- Review how report displays

**Review Existing Workbook Template**:

**Example: Microsoft Entra Sign-In Logs Workbook**:
- Select template in Templates section
- Select View template in details pane
- Contains predefined charts, graphs, tables
- Provides insight about sign-in activity in Microsoft Entra ID
- Information: User sign-ins and locations, email addresses, IP addresses
- Review information: Failed activities and triggering errors

**Features**:
- Expand time range
- Filter apps and users with sign-in privileges
- Example: Identify users signing in to Azure portal
- Display failed sign-in attempts by selecting information tiles

**Information Tiles Include**:
- **Sign-ins by location**: Location where user signed in
- **Location sign-in details**: Users, sign-in status, time of attempt
- **Sign-ins by device**: Devices used by users
- **Device sign-in details**: Users signed in on particular device and time
- **Conditional Access**: Users who signed in using Conditional Access
- **Conditional access status table**: Users requiring multifactor authentication

**Interactive Tables**:
- Select rows or tiles to filter presented data
- Some tables created with links to corresponding logs

**Note**: Can pin query step in private or shared dashboard for quick retrieval

**Edit Query from Workbook**:
- Select link to explore more information
- Redirected to Azure Data Explorer
- Microsoft Sentinel performs log query to filter information

**Explore Saved Workbooks**:

**Save Workbook**:
- From Templates page, select template
- Select Save
- Provide location for saving
- Creates Azure resource based on template with template's JSON file

**Saved Workbooks**:
- Available on My Workbooks tab
- Can customize
- Open by selecting View saved workbook

**Customize Saved Workbook**:
- Select Edit to open in edit mode
- Add or remove items
- Provide more customization
- Editing mode displays all content (steps and parameters hidden in reading mode)

**Header Bar in Editing Mode**:
- Multiple options available
- Select Edit options to examine individual workbook aspects
- Examine query used by Microsoft Sentinel to filter data from corresponding log
- Select settings icon: Opens Settings page (provide other resources, change style, provide tagging, pin items)
- Rearrange table placement: Select Show Pin Options
- Advanced customization: Select Advanced Editor (opens JSON representation for text editor customization)
- Save changes in existing workbook or save as another workbook
- Exit edit mode: Select Done Editing

**Microsoft Sentinel Repository on GitHub**:
- Contains out-of-box detections, exploration queries, hunting queries, workbooks, playbooks
- Help secure environment and detect threats
- Microsoft and community contribute
- Contains folders with contributed content for several Microsoft Sentinel functionality areas
- Use code from queries to create custom queries in workspace

### Create a New Microsoft Sentinel Workbook

**Custom Workbook Creation**:
- Create from scratch instead of using built-in templates
- Produce highly interactive reports containing texts, analytic queries, metrics, parameters

**Create Custom Workbook**:
- From Workbooks page in Microsoft Sentinel
- Select +Add workbook on header bar
- New workbook page opens with basic analytics query

**Tip**: Azure portal saves each created workbook as workbook resource in Microsoft Sentinel resource group

**Build Workbook**:
- Select Edit on New Workbook page
- Select Edit option to change text in new workbook template

**Visualization Types and Elements**:
- Text
- Query
- Parameters
- Links/tabs
- Metric

**Add New Element**:
- Select +Add

**Text Visualizations**:
- Use text blocks to interpret security data, section headings, telemetry data, other information
- Edit text using Markdown markup language (provides different formatting options for headings, font styles, hyperlinks, tables)
- After adding text, select Preview tab to preview content appearance
- Complete editing: Select Done Editing option

**Query Item**:

**Create Different Query**:
- Write query using KQL
- Format data using various visualizations:
  - Grids (tables)
  - Area charts
  - Bar charts
  - Line charts
  - Pie charts
  - Scatter charts
  - Time charts
  - Tiles

**Query Creation**:
- Microsoft Sentinel adds new Run Query step to workbook

**Header Bar Fields**:

| Name | Description |
|------|-------------|
| Run Query | Test result of query |
| Samples | Sample code with sample queries to add to workbook |
| Data Source | Specify data source for query |
| Resource type | Select type of resource |
| Log Analytics workspace | Query data against more than one resource |
| Time Range | Specify time range parameter for query |
| Visualization | Choose specific visualization or Set by query for different format |
| Size | Choose size of visualization element |

**Advanced Settings Tab**:
- Provide more customization for settings and styles
- Modify properties (e.g., enter Chart title)

**Style Tab**:
- Adjust margin and padding element in step
- After customization, save step: Select Done Editing

**Chart Visualizations**:

**Customizable Elements**:
- Height
- Width
- Color palette
- Legend
- Titles
- Axis types and series

**Example** (counts security alerts, visualizes in pie chart):
```kql
SecurityAlert
| where TimeGenerated >= ago(180d)
| summarize Count=count() by AlertSeverity
| render piechart
```

**Query Flexibility**:
- Include render parameter to indicate visualization type
- Use query without render parameter
- Use Visualization dropdown menu to select visualization type

**Grid Visualizations**:
- Select Grid visualization option from Visualization dropdown
- Present data in tables with enriched UI for reports
- Select Column Settings to specify displayed columns and provide column labels
- Edit Column settings tab: Select different column renderer (heatmap, bar, spark area)
- Select Custom formatting: Set units, style, formatting options for number values

**Parameters**:

**Purpose**:
- Manipulate query results in different ways in interactive workbook
- Select Add Parameter: Opens New Parameter page (provide name and required inputs)

**Parameter Types**:
- **Text**: Enter arbitrary text
- **Drop down**: Modify query step appearance; select value from set; enter KQL query or JSON string for choices
- **Time range picker**: Select from prepopulated ranges or custom range
- **Resource picker**: Select one or more Azure resources
- **Subscription picker**: Select one or more Azure subscription resources
- **Resource type picker**: Select one or more Azure resource type values
- **Location picker**: Select one or more Azure location values
- **Options group**: Group multiple properties
- **Tabs**: Tab-based organization
- **Multi-value**: Multiple value selection

**Reference Parameter Values**:
- Use in other workbook parts by using bindings or value expansions
- New Parameter pane Previews section: Review variables displayed and used in query code

**Links/Tabs**:

**Purpose**:
- Customize navigation with tabs, lists, paragraphs, bullet lists

**Inputs**:
- **Text before link**: Display text before link selected
- **Link text**: Actual text displayed in link
- **Text after link**: Text displayed after link selected
- **Action**: Action performed when link selected (Url, Set parameter value, Scroll to step)
- **Value**: Value for link
- **Settings**: Configure specific settings based on link type (support parameters syntax)
- **Context pane?**: Open new context panel to side instead of full view
- **Style**: Select between Link, Button (primary), Button (secondary) styles

**Metric Steps**:
- Combine workbook results with metrics from different Azure resources
- After all custom modifications, save workbook: Select Done Editing

## VIII. Manage Content in Microsoft Sentinel

### Use Solutions from Content Hub

**Content Hub Overview**:
- Centrally discover and install out-of-box (built-in) content
- Provides in-product discoverability, single-step deployment
- Enables end-to-end product, domain, vertical out-of-box solutions and content

**Features**:
- Filter by categories and other parameters
- Use powerful text search to find content for organization needs
- Indicates support model for each content piece (Microsoft, partners, or community maintained)
- Manage updates for out-of-box content via Content hub
- Manage updates for custom content via Repositories page

**Custom Content**:
- Customize out-of-box content for specific needs
- Create custom content: Analytics rules, hunting queries, notebooks, workbooks
- Manage directly in Microsoft Sentinel workspace
- Manage via Microsoft Sentinel API
- Manage in own source control repository via Repositories page

**Solutions**:

**Definition**:
- Packaged content or integrations delivering end-to-end product value
- For one or more domain or vertical scenarios

**Powered By**:
- Azure Marketplace for solutions' discoverability and deployment

**Solution Types**:

**1. Packaged Content**:
- Collections of one or more Microsoft Sentinel content pieces
- Includes: Data connectors, workbooks, analytics rules, playbooks, hunting queries, watchlists, parsers

**2. Integrations**:
- Services or tools built using Microsoft Sentinel or Azure Log Analytics APIs
- Support integrations between Azure and existing customer applications
- Migrate data, queries from applications into Microsoft Sentinel

**Benefits**:
- Install packages of out-of-box content in single step
- Content often ready to use immediately
- Providers and partners can productize investments
- Deliver combined product, domain, or vertical value

**Find a Solution**:

**Access**:
1. From Microsoft Sentinel navigation menu, under Content management, select Content hub
2. Content hub page displays searchable and filterable grid of solutions

**Filtering**:
- Select specific values from filters
- Enter part of solution name or description in Search field
- Each solution shows: Applied categories, types of content included

**Example**: Cisco Umbrella solution shows:
- Category: Security - Others
- Content: 10 analytics rules, 11 hunting queries, parser, 3 playbooks, more

**Install or Update a Solution**:

**Steps**:
1. Select solution in content hub to view more information on right
2. Select Install or Update if updates needed
3. On solution details page, select Create or Update (starts solution wizard)
4. On Basics tab: Enter subscription, resource group, workspace for deployment
5. Select Next to cycle through remaining tabs (corresponding to included components)
6. Learn about and configure each content component (in some cases)
7. On Review + create tab: Wait for "Validation Passed" message
8. Select Create or Update to deploy solution
9. Alternative: Select "Download a template for automation" link to deploy solution as code

### Use Repositories for Deployment

**Custom Content Management**:
- Store and manage in own Microsoft Sentinel workspaces
- Store in external source control repository (GitHub, Azure DevOps)
- Managing in external repository: Make updates outside Microsoft Sentinel, automatically deploy to workspaces

**Prerequisites and Scope**:

**Before Connecting Workspace to External Repository**:
- Access to GitHub or Azure DevOps repository with custom content files in relevant ARM templates
- Microsoft Sentinel currently supports connections only with GitHub and Azure DevOps
- Owner role in resource group containing Microsoft Sentinel workspace (required to create connection)
- Alternative to Owner role: Combination of User Access Administrator and Sentinel Contributor roles
- Maximum connections: 5 per Microsoft Sentinel workspace
- Deployment history limit: 800 deployments per Azure resource group (may see Deployment QuotaExceeded error with high ARM template volume)

**Validate Your Content**:
- Deploying via repository connection doesn't validate content (only verifies correct ARM template format)
- Recommendation: Validate content templates using regular validation process
- Can use Microsoft Sentinel GitHub validation process and tools to set up own validation process

**Connect a Repository**:

**Purpose**:
- Connect GitHub or Azure DevOps repository to Microsoft Sentinel workspace
- Save and manage custom content instead of in Microsoft Sentinel

**Connection Support**:
- Each connection supports multiple custom content types: Analytics rules, automation rules, hunting queries, parsers, playbooks, workbooks

**Steps to Create Connection**:

**1. Sign In**:
- Ensure signed into source control app with credentials for connection
- If using different credentials, sign out first

**2. Access Repositories**:
- In Microsoft Sentinel, under Content management, select Repositories
- Select Add new
- On Create new connection page: Enter meaningful name and description

**3. Configure Connection**:

**GitHub Option**:
- From Source Control dropdown, select type (GitHub)
- Select Authorize
- Enter GitHub credentials when prompted
- First time: New browser window/tab prompts to authorize connection
- If already logged into GitHub: Credentials auto-populated
- Repository area shows on Create new connection page
- Select existing repository from list
- Select Add repository
- First time connecting to specific repository: New window/tab prompts to install Azure-Sentinel app
- If multiple repositories: Select where to install Azure-Sentinel app
- Install app
- Directed to GitHub to continue installation
- After installation: Branch dropdown populated with branches
- Select branch to connect to workspace
- From Content Types dropdown: Select type of content deploying
- Note: Parsers and hunting queries use Saved Searches API (if select one type and have other type in branch, both types deployed)
- For all other content types: Selecting type deploys only that content; other types not deployed
- Select Create to create connection

**Azure DevOps Option**:
- Automatically authorized using current Azure credentials
- Verify authorization to same Azure DevOps organization connecting from Microsoft Sentinel
- Alternative: Use InPrivate browser window to create connection
- From dropdown lists: Select Organization, Project, Repository, Branch, Content Types
- Note: Parsers and hunting queries use Saved Searches API (if select one type and have other type in branch, both types deployed)
- For all other content types: Selecting type deploys only that content; other types not deployed
- Select Create to create connection

**4. After Connection Created**:
- New workflow or pipeline generated in repository
- Content stored in repository deployed to Microsoft Sentinel workspace
- Deployment time varies depending on content volume

---

**End of Document**
